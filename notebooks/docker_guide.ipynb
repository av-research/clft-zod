{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221593db",
   "metadata": {},
   "source": [
    "# Docker Configuration Guide for CLFT ZOD Project\n",
    "\n",
    "This notebook explains the Docker setup for the CLFT ZOD project. The setup provides both lightweight CPU-only and GPU-enabled CUDA environments for different use cases.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The project includes three main Docker configuration files:\n",
    "- **`Dockerfile.lite`**: Lightweight CPU-only container for basic data exploration\n",
    "- **`Dockerfile.cuda`**: GPU-enabled container with CUDA support for deep learning\n",
    "- **`compose.yml`**: Docker Compose configuration managing both services\n",
    "\n",
    "This setup allows you to:\n",
    "- Quickly spin up development environments\n",
    "- Switch between CPU and GPU workloads\n",
    "- Ensure consistent dependencies across machines\n",
    "- Isolate project environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c32318",
   "metadata": {},
   "source": [
    "## Dockerfile.lite - Lightweight CPU Container\n",
    "\n",
    "The `Dockerfile.lite` creates a lightweight Python environment suitable for data exploration, analysis, and CPU-based machine learning tasks.\n",
    "\n",
    "### Base Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a227c4f-4fde-4e34-a8a8-e9ac64d56dff",
   "metadata": {},
   "source": [
    "# Lightweight Python container for data exploration with PyTorch support\n",
    "FROM python:3.12-slim\n",
    "\n",
    "# Set environment variables\n",
    "ENV PYTHONUNBUFFERED=1 \\\\\n",
    "    PYTHONDONTWRITEBYTECODE=1 \\\\\n",
    "    PIP_NO_CACHE_DIR=1 \\\\\n",
    "    DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && \\\\\n",
    "    apt-get install -y --no-install-recommends \\\\\n",
    "    build-essential \\\\\n",
    "    git \\\\\n",
    "    wget \\\\\n",
    "    curl \\\\\n",
    "    && apt-get clean \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Create working directory\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Install Python packages\n",
    "COPY requirements.txt* ./\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Copy project files (excluding files defined in .dockerignore)\n",
    "COPY . .\n",
    "\n",
    "# Expose Jupyter port\n",
    "EXPOSE 8888\n",
    "\n",
    "# Default command - can be overridden in compose.yml\n",
    "CMD [\"/bin/bash\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d2b65",
   "metadata": {},
   "source": [
    "## Dockerfile.cuda - GPU-Enabled Container\n",
    "\n",
    "The `Dockerfile.cuda` creates a GPU-enabled environment optimized for deep learning and CUDA-accelerated computing tasks.\n",
    "\n",
    "### NVIDIA Base Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4a2e69b-0f80-416b-911d-9a953bc0869a",
   "metadata": {},
   "source": [
    "# Uses NVIDIA's PyTorch container as base\n",
    "FROM nvcr.io/nvidia/pytorch:25.03-py3\n",
    "\n",
    "# Set basic environment variables\n",
    "ENV PYTHONUNBUFFERED=1 \\\\\n",
    "    PYTHONDONTWRITEBYTECODE=1\n",
    "\n",
    "# Install some common packages\n",
    "RUN apt-get update && \\\\\n",
    "    apt-get install -y --no-install-recommends \\\\\n",
    "    curl wget git libgl1 && \\\\\n",
    "    apt-get clean && \\\\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Create and set working directory\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Install pip packages\n",
    "RUN pip install timm\n",
    "\n",
    "# Copy the CUDA test script\n",
    "COPY cuda_test.py /workspace/\n",
    "\n",
    "# Default command - print info and run CUDA test\n",
    "CMD [\"python\", \"cuda_test.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff95de1f",
   "metadata": {},
   "source": [
    "## Docker Compose Configuration\n",
    "\n",
    "The `compose.yml` file orchestrates both containers, providing a unified interface to manage CPU and GPU environments.\n",
    "\n",
    "### Docker Compose file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5266dfa4-20ac-4eb3-9709-7cde0f505b9d",
   "metadata": {},
   "source": [
    "# compose.yml\n",
    "services:\n",
    "  # CPU-only service (lightweight, fast build)\n",
    "  python-lite:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile.lite\n",
    "    image: python-lite:latest\n",
    "    container_name: python-lite\n",
    "    volumes:\n",
    "      - ./:/workspace\n",
    "    environment:\n",
    "      - PYTHONPATH=/workspace\n",
    "    stdin_open: true\n",
    "    tty: true\n",
    "    ports:\n",
    "      - \"8888:8888\"\n",
    "    working_dir: /workspace  \n",
    "\n",
    "  # GPU-enabled service with CUDA support\n",
    "  python-cuda:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile.cuda\n",
    "    image: python-cuda:latest\n",
    "    container_name: python-cuda\n",
    "    volumes:\n",
    "      - ./:/workspace\n",
    "    environment:\n",
    "      - PYTHONPATH=/workspace\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "      - NVIDIA_DRIVER_CAPABILITIES=compute,utility\n",
    "      - CUDA_LAUNCH_BLOCKING=1\n",
    "      - TORCH_USE_CUDA_DSA=1\n",
    "      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n",
    "    stdin_open: true\n",
    "    tty: true\n",
    "    ports:\n",
    "      - \"8889:8888\"  # Different port to avoid conflicts\n",
    "    working_dir: /workspace\n",
    "    deploy:\n",
    "      resources:\n",
    "        reservations:\n",
    "          devices:\n",
    "            - driver: nvidia\n",
    "              count: all\n",
    "              capabilities: [gpu]\n",
    "    shm_size: '16g'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b754ab",
   "metadata": {},
   "source": [
    "## How to Use the Docker Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a5131",
   "metadata": {},
   "source": [
    "### Common Workflow Examples\n",
    "\n",
    "#### 1. Data Exploration Workflow (CPU)\n",
    "```bash\n",
    "# Build and start the lightweight container and access interactive shell\n",
    "docker compose run --rm --service-ports python-lite bash\n",
    "\n",
    "# Unpack ZOD dataset\n",
    "sh scripts/extract_zod_data.sh\n",
    "\n",
    "# Start Jupyter for interactive analysis\n",
    "sh scripts/jupyter_startup.sh\n",
    "```\n",
    "Access Jupyter at: `http://localhost:8888`\n",
    "\n",
    "#### 2. Deep Learning Training Workflow (GPU)\n",
    "```bash\n",
    "# Build and start GPU container\n",
    "docker compose run --rm --service-ports python-cuda bash\n",
    "\n",
    "# Verify GPU access\n",
    "python3 cuda_test.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
